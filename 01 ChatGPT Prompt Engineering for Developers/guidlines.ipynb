{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai \n",
    "import os \n",
    "from openai import OpenAI \n",
    "\n",
    "# openai.api_key  = os.getenv('API_KEY')\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv('API_KEY'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To guide a model towards the desired output and reduce irrelevant or incorrect responses, it is important to provide clear and specific instructions, which can be achieved through longer prompts that offer more clarity and context.\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "You should express what you want a model to do by \\ \n",
    "providing instructions that are as clear and \\ \n",
    "specific as you can possibly make them. \\ \n",
    "This will guide the model towards the desired output, \\ \n",
    "and reduce the chances of receiving irrelevant \\ \n",
    "or incorrect responses. Don't confuse writing a \\ \n",
    "clear prompt with writing a short prompt. \\ \n",
    "In many cases, longer prompts provide more clarity \\ \n",
    "and context for the model, which can lead to \\ \n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \\ \n",
    "into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"books\": [\n",
      "    {\n",
      "      \"book_id\": 1,\n",
      "      \"title\": \"The Enigma of Elysium\",\n",
      "      \"author\": \"Evelyn Sinclair\",\n",
      "      \"genre\": \"Mystery\"\n",
      "    },\n",
      "    {\n",
      "      \"book_id\": 2,\n",
      "      \"title\": \"Whispers in the Wind\",\n",
      "      \"author\": \"Nathaniel Blackwood\",\n",
      "      \"genre\": \"Fantasy\"\n",
      "    },\n",
      "    {\n",
      "      \"book_id\": 3,\n",
      "      \"title\": \"Echoes of the Past\",\n",
      "      \"author\": \"Amelia Hart\",\n",
      "      \"genre\": \"Romance\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Generate a list of three made-up book titles along \\ \n",
    "with their authors and genres. \n",
    "Provide them in JSON format with the following keys: \n",
    "book_id, title, author, genre.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A court case can reach the Supreme Court in a few different ways:\n",
      "\n",
      "1. Appeal from lower courts: Most cases that reach the Supreme Court are appeals from decisions of lower federal courts or state supreme courts. Typically there is a circuit split, an important constitutional issue, or federal law at stake for the Supreme Court to agree to hear the appeal.\n",
      "\n",
      "2. Original jurisdiction: The Supreme Court has original jurisdiction in limited kinds of cases, meaning the case is filed there first. These include cases between two or more states and cases involving ambassadors and other public ministers. These cases begin directly at the Supreme Court.\n",
      "\n",
      "3. Certiorari: This is the most common way cases reach the Supreme Court. If a party that lost in a lower court files a petition for a writ of certiorari, the Supreme Court has discretion on whether or not to hear the appeal. Four justices have to agree to \"grant cert\" for the court to hear it. Common reasons are because the case involves an important legal principle or there are conflicting rulings between courts.\n",
      "\n",
      "So in summary - Supreme Court cases typically start at lower federal and state courts, then make their way up on appeal, and require the Supreme Court's discretionary acceptance to be heard at that final stage. Cases can also start at the Supreme Court if they involve certain original jurisdiction scenarios.\n"
     ]
    }
   ],
   "source": [
    "from anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPT\n",
    "\n",
    "anthropic = Anthropic(\n",
    "    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "    api_key=\"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\",\n",
    ")\n",
    "\n",
    "completion = anthropic.completions.create(\n",
    "    model=\"claude-2.1\",\n",
    "    max_tokens_to_sample=300,\n",
    "    prompt=f\"{HUMAN_PROMPT} how does a court case get to the Supreme Court?{AI_PROMPT}\",\n",
    ")\n",
    "print(completion.completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_PROMPT = \"My name is Sean (林士桓), a dedicated AI engineer from Taiwan, currently serving in a PCB manufacturing. I possess profound expertise and passion in AI, encompassing training, deployment, and application. My competencies extend to image processing, object recognition, YOLO, deep learning, machine learning, OpenCV, PyTorch, CNN, feature extraction, image segmentation, and model fine-tuning. As a 30-year-old professional, I am not only enthusiastic about embracing new challenges but also consistently expanding my network. Currently, I am actively seeking opportunities to transition to an overseas company, aspiring to further enhance my professional capabilities and career progression.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Meanwhile, I am willing to provide consultation and support to SMEs and startups interested in adopting AI for operational efficiency. Your consideration would be greatly appreciated!"
     ]
    }
   ],
   "source": [
    "from anthropic import AsyncAnthropic, HUMAN_PROMPT, AI_PROMPT\n",
    "\n",
    "anthropic = AsyncAnthropic(\n",
    "    api_key=\"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\",\n",
    ")\n",
    "\n",
    "stream = await anthropic.completions.create(\n",
    "    prompt= f'{HUMAN_PROMPT}什麼是量子力學?{AI_PROMPT}My name is Sean (林士桓), a dedicated AI engineer from Taiwan, currently serving in a PCB manufacturing. I possess profound expertise and passion in AI, encompassing training, deployment, and application. My competencies extend to image processing, object recognition, YOLO, deep learning, machine learning, OpenCV, PyTorch, CNN, feature extraction, image segmentation, and model fine-tuning. As a 30-year-old professional, I am not only enthusiastic about embracing new challenges but also consistently expanding my network. Currently, I am actively seeking opportunities to transition to an overseas company, aspiring to further enhance my professional capabilities and career progression.',\n",
    "    max_tokens_to_sample=300,\n",
    "    model=\"claude-2.1\",\n",
    "    stream=True,\n",
    ")\n",
    "async for completion in stream:\n",
    "    print(completion.completion, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import AsyncAnthropic, HUMAN_PROMPT, AI_PROMPT\n",
    "\n",
    "anthropic = AsyncAnthropic(\n",
    "    api_key=\"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\",\n",
    ")\n",
    "\n",
    "stream = await anthropic.completions.create(\n",
    "    prompt=f\"{HUMAN_PROMPT} Your prompt here{AI_PROMPT}\",\n",
    "    max_tokens_to_sample=300,\n",
    "    model=\"claude-2.1\",\n",
    "    stream=True,\n",
    ")\n",
    "async for completion in stream:\n",
    "    print(completion.completion, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
